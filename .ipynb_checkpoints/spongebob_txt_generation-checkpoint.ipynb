{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PyTorch to Generate Spongebob Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. import libraries we will depend on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Set variables for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = Namespace(\n",
    "    train_file='spongebob-transcript.txt',\n",
    "    seq_size=32,\n",
    "    batch_size=16,\n",
    "    embedding_size=64,\n",
    "    lstm_size=64,\n",
    "    gradients_norm=5,\n",
    "    initial_words=['_________________________________________________________'],\n",
    "    predict_top_k=5,\n",
    "    checkpoint_path='checkpoint'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a function to process the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_from_file(train_file, batch_size, seq_size):\n",
    "    with open(train_file, 'r') as file:\n",
    "        text = file.read()\n",
    "    text = text.split()\n",
    "    \n",
    "    word_counts = Counter(text)\n",
    "    \n",
    "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    int_to_vocab = {k: w for k, w in enumerate(sorted_vocab)}\n",
    "    vocab_to_int = {w: k for k, w in int_to_vocab.items()}\n",
    "    n_vocab = len(int_to_vocab)\n",
    "    \n",
    "    int_text = [vocab_to_int[w] for w in text]\n",
    "    num_batches = int(len(int_text) / (seq_size * batch_size))\n",
    "    in_text = int_text[:num_batches * batch_size * seq_size]\n",
    "    out_text = np.zeros_like(in_text)\n",
    "    out_text[:-1] = in_text[1:]\n",
    "    out_text[-1] = in_text[0]\n",
    "    in_text = np.reshape(in_text, (batch_size, -1))\n",
    "    out_text = np.reshape(out_text, (batch_size, -1))\n",
    "    \n",
    "    return int_to_vocab, vocab_to_int, n_vocab, in_text, out_text\n",
    "\n",
    "#Call the function and set some variables\n",
    "device = torch.device('cpu')\n",
    "int_to_vocab, vocab_to_int, n_vocab, in_text, out_text = process_data_from_file(flags.train_file, flags.batch_size, flags.seq_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Take a look at some of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:\n",
      " 71566\n",
      "Out Text Matrix:\n",
      " [[12942   265 23161 ...   543   227    72]\n",
      " [  647    82   196 ...     1    89    30]\n",
      " [    8     3  4628 ...   188    70 15392]\n",
      " ...\n",
      " [ 2404    22    76 ... 11386    29  8081]\n",
      " [ 1060   131     0 ...  4740     5 14194]\n",
      " [ 7903  4002   203 ...   182   626  2083]]\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary size:\\n', n_vocab)\n",
    "print('Out Text Matrix:\\n', out_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. Now let's:\n",
    "5. Create the network in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModule(nn.Module):\n",
    "    #define necessary layers in the constructor:\n",
    "    #embedding layer, LSTM layer, dense layer\n",
    "    def __init__(self, n_vocab, seq_size, embedding_size, lstm_size):\n",
    "        super(RNNModule, self).__init__()\n",
    "        self.seq_size = seq_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, lstm_size, batch_first=True)\n",
    "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
    "    \n",
    "    #define function for forward pass\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.dense(output)\n",
    "        return logits, state\n",
    "    \n",
    "    #define function to reset state at each epoch\n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.lstm_size),\n",
    "                torch.zeros(1, batch_size, self.lstm_size))\n",
    "\n",
    "#Instantiate the network\n",
    "net = RNNModule(n_vocab, flags.seq_size, flags.embedding_size, flags.lstm_size)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Define a function to handle loss and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_and_train_op(net, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    return criterion, optimizer\n",
    "\n",
    "#Call the function\n",
    "criterion, optimizer = get_loss_and_train_op(net, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Define the function to get batches for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(in_text, out_text, batch_size, seq_size):\n",
    "    num_batches = np.prod(in_text.shape) // (seq_size * batch_size)\n",
    "    for i in range(0, num_batches * seq_size, seq_size):\n",
    "        yield in_text[:, i:i+seq_size], out_text[:, i:i+seq_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Define the prediction function which will be used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(device, net, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
    "    # tells the network we are about to evaluate\n",
    "    net.eval()\n",
    "    \n",
    "    state_h, state_c = net.zero_state(1)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    for w in words:\n",
    "        ix = torch.tensor([[vocab_to_int[w]]]).to(device)\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "    \n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "    choice = np.random.choice(choices[0])\n",
    "    \n",
    "    # append another word\n",
    "    words.append(int_to_vocab[choice])\n",
    "    \n",
    "    # append 100 more\n",
    "    for _ in range(100):\n",
    "        ix = torch.tensor([[choice]]).to(device)\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "        \n",
    "        _, top_ix = torch.topk(output[0], k=top_k)\n",
    "        choices = top_ix.tolist()\n",
    "        choice = np.random.choice(choices[0])\n",
    "        words.append(int_to_vocab[choice])\n",
    "    \n",
    "    print(' '.join(words))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Training! Loop through batches for each epoch, compute losses and update network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Iteration:  1\n",
      "Iteration:  2\n",
      "Iteration:  3\n",
      "Iteration:  4\n",
      "Iteration:  5\n",
      "Iteration:  6\n",
      "Iteration:  7\n",
      "Iteration:  8\n",
      "Iteration:  9\n",
      "Iteration:  10\n",
      "Iteration:  11\n",
      "Iteration:  12\n",
      "Iteration:  13\n",
      "Iteration:  14\n",
      "Iteration:  15\n",
      "Iteration:  16\n",
      "Iteration:  17\n",
      "Iteration:  18\n",
      "Iteration:  19\n",
      "Iteration:  20\n",
      "Iteration:  21\n",
      "Iteration:  22\n",
      "Iteration:  23\n",
      "Iteration:  24\n",
      "Iteration:  25\n",
      "Iteration:  26\n",
      "Iteration:  27\n",
      "Iteration:  28\n",
      "Iteration:  29\n",
      "Iteration:  30\n",
      "Iteration:  31\n",
      "Iteration:  32\n",
      "Iteration:  33\n",
      "Iteration:  34\n",
      "Iteration:  35\n",
      "Iteration:  36\n",
      "Iteration:  37\n",
      "Iteration:  38\n",
      "Iteration:  39\n",
      "Iteration:  40\n",
      "Iteration:  41\n",
      "Iteration:  42\n",
      "Iteration:  43\n",
      "Iteration:  44\n",
      "Iteration:  45\n",
      "Iteration:  46\n",
      "Iteration:  47\n",
      "Iteration:  48\n",
      "Iteration:  49\n",
      "Iteration:  50\n",
      "Iteration:  51\n",
      "Iteration:  52\n",
      "Iteration:  53\n",
      "Iteration:  54\n",
      "Iteration:  55\n",
      "Iteration:  56\n",
      "Iteration:  57\n",
      "Iteration:  58\n",
      "Iteration:  59\n",
      "Iteration:  60\n",
      "Iteration:  61\n",
      "Iteration:  62\n",
      "Iteration:  63\n",
      "Iteration:  64\n",
      "Iteration:  65\n",
      "Iteration:  66\n",
      "Iteration:  67\n",
      "Iteration:  68\n",
      "Iteration:  69\n",
      "Iteration:  70\n",
      "Iteration:  71\n",
      "Iteration:  72\n",
      "Iteration:  73\n",
      "Iteration:  74\n",
      "Iteration:  75\n",
      "Iteration:  76\n",
      "Iteration:  77\n",
      "Iteration:  78\n",
      "Iteration:  79\n",
      "Iteration:  80\n",
      "Iteration:  81\n",
      "Iteration:  82\n",
      "Iteration:  83\n",
      "Iteration:  84\n",
      "Iteration:  85\n",
      "Iteration:  86\n",
      "Iteration:  87\n",
      "Iteration:  88\n",
      "Iteration:  89\n",
      "Iteration:  90\n",
      "Iteration:  91\n",
      "Iteration:  92\n",
      "Iteration:  93\n",
      "Iteration:  94\n",
      "Iteration:  95\n",
      "Iteration:  96\n",
      "Iteration:  97\n",
      "Iteration:  98\n",
      "Iteration:  99\n",
      "Iteration:  100\n",
      "Epoch: 0/200 Iteration: 100 Loss: 7.63424825668335\n",
      "Iteration:  101\n",
      "Iteration:  102\n",
      "Iteration:  103\n",
      "Iteration:  104\n",
      "Iteration:  105\n",
      "Iteration:  106\n",
      "Iteration:  107\n",
      "Iteration:  108\n",
      "Iteration:  109\n",
      "Iteration:  110\n",
      "Iteration:  111\n",
      "Iteration:  112\n",
      "Iteration:  113\n",
      "Iteration:  114\n",
      "Iteration:  115\n",
      "Iteration:  116\n",
      "Iteration:  117\n",
      "Iteration:  118\n",
      "Iteration:  119\n",
      "Iteration:  120\n",
      "Iteration:  121\n",
      "Iteration:  122\n",
      "Iteration:  123\n",
      "Iteration:  124\n",
      "Iteration:  125\n",
      "Iteration:  126\n",
      "Iteration:  127\n",
      "Iteration:  128\n",
      "Iteration:  129\n",
      "Iteration:  130\n",
      "Iteration:  131\n",
      "Iteration:  132\n",
      "Iteration:  133\n",
      "Iteration:  134\n",
      "Iteration:  135\n",
      "Iteration:  136\n",
      "Iteration:  137\n",
      "Iteration:  138\n",
      "Iteration:  139\n",
      "Iteration:  140\n",
      "Iteration:  141\n",
      "Iteration:  142\n",
      "Iteration:  143\n",
      "Iteration:  144\n",
      "Iteration:  145\n",
      "Iteration:  146\n",
      "Iteration:  147\n",
      "Iteration:  148\n",
      "Iteration:  149\n",
      "Iteration:  150\n",
      "Iteration:  151\n",
      "Iteration:  152\n",
      "Iteration:  153\n",
      "Iteration:  154\n",
      "Iteration:  155\n",
      "Iteration:  156\n",
      "Iteration:  157\n",
      "Iteration:  158\n",
      "Iteration:  159\n",
      "Iteration:  160\n",
      "Iteration:  161\n",
      "Iteration:  162\n",
      "Iteration:  163\n",
      "Iteration:  164\n",
      "Iteration:  165\n",
      "Iteration:  166\n",
      "Iteration:  167\n",
      "Iteration:  168\n",
      "Iteration:  169\n",
      "Iteration:  170\n",
      "Iteration:  171\n",
      "Iteration:  172\n",
      "Iteration:  173\n",
      "Iteration:  174\n",
      "Iteration:  175\n",
      "Iteration:  176\n",
      "Iteration:  177\n",
      "Iteration:  178\n",
      "Iteration:  179\n",
      "Iteration:  180\n",
      "Iteration:  181\n",
      "Iteration:  182\n",
      "Iteration:  183\n",
      "Iteration:  184\n",
      "Iteration:  185\n",
      "Iteration:  186\n",
      "Iteration:  187\n",
      "Iteration:  188\n",
      "Iteration:  189\n",
      "Iteration:  190\n",
      "Iteration:  191\n",
      "Iteration:  192\n",
      "Iteration:  193\n",
      "Iteration:  194\n",
      "Iteration:  195\n",
      "Iteration:  196\n",
      "Iteration:  197\n",
      "Iteration:  198\n",
      "Iteration:  199\n",
      "Iteration:  200\n",
      "Epoch: 0/200 Iteration: 200 Loss: 7.116626262664795\n",
      "Iteration:  201\n",
      "Iteration:  202\n",
      "Iteration:  203\n",
      "Iteration:  204\n",
      "Iteration:  205\n",
      "Iteration:  206\n",
      "Iteration:  207\n",
      "Iteration:  208\n",
      "Iteration:  209\n",
      "Iteration:  210\n",
      "Iteration:  211\n",
      "Iteration:  212\n",
      "Iteration:  213\n",
      "Iteration:  214\n",
      "Iteration:  215\n",
      "Iteration:  216\n",
      "Iteration:  217\n",
      "Iteration:  218\n",
      "Iteration:  219\n",
      "Iteration:  220\n",
      "Iteration:  221\n",
      "Iteration:  222\n",
      "Iteration:  223\n",
      "Iteration:  224\n",
      "Iteration:  225\n",
      "Iteration:  226\n",
      "Iteration:  227\n",
      "Iteration:  228\n",
      "Iteration:  229\n",
      "Iteration:  230\n",
      "Iteration:  231\n",
      "Iteration:  232\n",
      "Iteration:  233\n",
      "Iteration:  234\n",
      "Iteration:  235\n",
      "Iteration:  236\n",
      "Iteration:  237\n",
      "Iteration:  238\n",
      "Iteration:  239\n",
      "Iteration:  240\n",
      "Iteration:  241\n",
      "Iteration:  242\n",
      "Iteration:  243\n",
      "Iteration:  244\n",
      "Iteration:  245\n",
      "Iteration:  246\n",
      "Iteration:  247\n",
      "Iteration:  248\n",
      "Iteration:  249\n",
      "Iteration:  250\n",
      "Iteration:  251\n",
      "Iteration:  252\n",
      "Iteration:  253\n",
      "Iteration:  254\n",
      "Iteration:  255\n",
      "Iteration:  256\n",
      "Iteration:  257\n",
      "Iteration:  258\n",
      "Iteration:  259\n",
      "Iteration:  260\n",
      "Iteration:  261\n",
      "Iteration:  262\n",
      "Iteration:  263\n",
      "Iteration:  264\n",
      "Iteration:  265\n",
      "Iteration:  266\n",
      "Iteration:  267\n",
      "Iteration:  268\n",
      "Iteration:  269\n",
      "Iteration:  270\n",
      "Iteration:  271\n",
      "Iteration:  272\n",
      "Iteration:  273\n",
      "Iteration:  274\n",
      "Iteration:  275\n",
      "Iteration:  276\n",
      "Iteration:  277\n",
      "Iteration:  278\n",
      "Iteration:  279\n",
      "Iteration:  280\n",
      "Iteration:  281\n",
      "Iteration:  282\n",
      "Iteration:  283\n",
      "Iteration:  284\n",
      "Iteration:  285\n",
      "Iteration:  286\n",
      "Iteration:  287\n",
      "Iteration:  288\n",
      "Iteration:  289\n",
      "Iteration:  290\n",
      "Iteration:  291\n",
      "Iteration:  292\n",
      "Iteration:  293\n",
      "Iteration:  294\n",
      "Iteration:  295\n",
      "Iteration:  296\n",
      "Iteration:  297\n",
      "Iteration:  298\n",
      "Iteration:  299\n",
      "Iteration:  300\n",
      "Epoch: 0/200 Iteration: 300 Loss: 7.184117317199707\n",
      "Iteration:  301\n",
      "Iteration:  302\n",
      "Iteration:  303\n",
      "Iteration:  304\n",
      "Iteration:  305\n",
      "Iteration:  306\n",
      "Iteration:  307\n",
      "Iteration:  308\n",
      "Iteration:  309\n",
      "Iteration:  310\n",
      "Iteration:  311\n",
      "Iteration:  312\n",
      "Iteration:  313\n",
      "Iteration:  314\n",
      "Iteration:  315\n",
      "Iteration:  316\n",
      "Iteration:  317\n",
      "Iteration:  318\n",
      "Iteration:  319\n",
      "Iteration:  320\n",
      "Iteration:  321\n",
      "Iteration:  322\n",
      "Iteration:  323\n",
      "Iteration:  324\n",
      "Iteration:  325\n",
      "Iteration:  326\n",
      "Iteration:  327\n",
      "Iteration:  328\n",
      "Iteration:  329\n",
      "Iteration:  330\n",
      "Iteration:  331\n",
      "Iteration:  332\n",
      "Iteration:  333\n",
      "Iteration:  334\n",
      "Iteration:  335\n",
      "Iteration:  336\n",
      "Iteration:  337\n",
      "Iteration:  338\n",
      "Iteration:  339\n",
      "Iteration:  340\n",
      "Iteration:  341\n",
      "Iteration:  342\n",
      "Iteration:  343\n",
      "Iteration:  344\n",
      "Iteration:  345\n",
      "Iteration:  346\n",
      "Iteration:  347\n",
      "Iteration:  348\n",
      "Iteration:  349\n",
      "Iteration:  350\n",
      "Iteration:  351\n",
      "Iteration:  352\n",
      "Iteration:  353\n",
      "Iteration:  354\n",
      "Iteration:  355\n",
      "Iteration:  356\n",
      "Iteration:  357\n",
      "Iteration:  358\n",
      "Iteration:  359\n",
      "Iteration:  360\n",
      "Iteration:  361\n",
      "Iteration:  362\n",
      "Iteration:  363\n",
      "Iteration:  364\n",
      "Iteration:  365\n",
      "Iteration:  366\n",
      "Iteration:  367\n",
      "Iteration:  368\n",
      "Iteration:  369\n",
      "Iteration:  370\n",
      "Iteration:  371\n",
      "Iteration:  372\n",
      "Iteration:  373\n",
      "Iteration:  374\n",
      "Iteration:  375\n",
      "Iteration:  376\n",
      "Iteration:  377\n",
      "Iteration:  378\n",
      "Iteration:  379\n",
      "Iteration:  380\n",
      "Iteration:  381\n",
      "Iteration:  382\n",
      "Iteration:  383\n",
      "Iteration:  384\n",
      "Iteration:  385\n",
      "Iteration:  386\n",
      "Iteration:  387\n",
      "Iteration:  388\n",
      "Iteration:  389\n",
      "Iteration:  390\n",
      "Iteration:  391\n",
      "Iteration:  392\n",
      "Iteration:  393\n",
      "Iteration:  394\n",
      "Iteration:  395\n",
      "Iteration:  396\n",
      "Iteration:  397\n",
      "Iteration:  398\n",
      "Iteration:  399\n",
      "Iteration:  400\n",
      "Epoch: 0/200 Iteration: 400 Loss: 7.058692455291748\n",
      "Iteration:  401\n",
      "Iteration:  402\n",
      "Iteration:  403\n",
      "Iteration:  404\n",
      "Iteration:  405\n",
      "Iteration:  406\n",
      "Iteration:  407\n",
      "Iteration:  408\n",
      "Iteration:  409\n",
      "Iteration:  410\n",
      "Iteration:  411\n",
      "Iteration:  412\n",
      "Iteration:  413\n",
      "Iteration:  414\n",
      "Iteration:  415\n",
      "Iteration:  416\n",
      "Iteration:  417\n",
      "Iteration:  418\n",
      "Iteration:  419\n",
      "Iteration:  420\n",
      "Iteration:  421\n",
      "Iteration:  422\n",
      "Iteration:  423\n",
      "Iteration:  424\n",
      "Iteration:  425\n",
      "Iteration:  426\n",
      "Iteration:  427\n",
      "Iteration:  428\n",
      "Iteration:  429\n",
      "Iteration:  430\n",
      "Iteration:  431\n",
      "Iteration:  432\n",
      "Iteration:  433\n",
      "Iteration:  434\n",
      "Iteration:  435\n",
      "Iteration:  436\n",
      "Iteration:  437\n",
      "Iteration:  438\n",
      "Iteration:  439\n",
      "Iteration:  440\n",
      "Iteration:  441\n",
      "Iteration:  442\n",
      "Iteration:  443\n",
      "Iteration:  444\n",
      "Iteration:  445\n",
      "Iteration:  446\n",
      "Iteration:  447\n",
      "Iteration:  448\n",
      "Iteration:  449\n",
      "Iteration:  450\n",
      "Iteration:  451\n",
      "Iteration:  452\n",
      "Iteration:  453\n",
      "Iteration:  454\n",
      "Iteration:  455\n",
      "Iteration:  456\n",
      "Iteration:  457\n",
      "Iteration:  458\n",
      "Iteration:  459\n",
      "Iteration:  460\n",
      "Iteration:  461\n",
      "Iteration:  462\n",
      "Iteration:  463\n",
      "Iteration:  464\n",
      "Iteration:  465\n",
      "Iteration:  466\n",
      "Iteration:  467\n",
      "Iteration:  468\n",
      "Iteration:  469\n",
      "Iteration:  470\n",
      "Iteration:  471\n",
      "Iteration:  472\n",
      "Iteration:  473\n",
      "Iteration:  474\n",
      "Iteration:  475\n",
      "Iteration:  476\n",
      "Iteration:  477\n",
      "Iteration:  478\n",
      "Iteration:  479\n",
      "Iteration:  480\n",
      "Iteration:  481\n",
      "Iteration:  482\n",
      "Iteration:  483\n",
      "Iteration:  484\n",
      "Iteration:  485\n",
      "Iteration:  486\n",
      "Iteration:  487\n",
      "Iteration:  488\n",
      "Iteration:  489\n",
      "Iteration:  490\n",
      "Iteration:  491\n",
      "Iteration:  492\n",
      "Iteration:  493\n",
      "Iteration:  494\n",
      "Iteration:  495\n",
      "Iteration:  496\n",
      "Iteration:  497\n",
      "Iteration:  498\n",
      "Iteration:  499\n",
      "Iteration:  500\n",
      "Epoch: 0/200 Iteration: 500 Loss: 7.05047082901001\n",
      "Iteration:  501\n",
      "Iteration:  502\n",
      "Iteration:  503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  504\n",
      "Iteration:  505\n",
      "Iteration:  506\n",
      "Iteration:  507\n",
      "Iteration:  508\n",
      "Iteration:  509\n",
      "Iteration:  510\n",
      "Iteration:  511\n",
      "Iteration:  512\n",
      "Iteration:  513\n",
      "Iteration:  514\n",
      "Iteration:  515\n",
      "Iteration:  516\n",
      "Iteration:  517\n",
      "Iteration:  518\n",
      "Iteration:  519\n",
      "Iteration:  520\n",
      "Iteration:  521\n",
      "Iteration:  522\n",
      "Iteration:  523\n",
      "Iteration:  524\n",
      "Iteration:  525\n",
      "Iteration:  526\n",
      "Iteration:  527\n",
      "Iteration:  528\n",
      "Iteration:  529\n",
      "Iteration:  530\n",
      "Iteration:  531\n",
      "Iteration:  532\n",
      "Iteration:  533\n",
      "Iteration:  534\n",
      "Iteration:  535\n",
      "Iteration:  536\n",
      "Iteration:  537\n",
      "Iteration:  538\n",
      "Iteration:  539\n",
      "Iteration:  540\n",
      "Iteration:  541\n",
      "Iteration:  542\n",
      "Iteration:  543\n",
      "Iteration:  544\n",
      "Iteration:  545\n",
      "Iteration:  546\n",
      "Iteration:  547\n",
      "Iteration:  548\n",
      "Iteration:  549\n",
      "Iteration:  550\n",
      "Iteration:  551\n",
      "Iteration:  552\n",
      "Iteration:  553\n",
      "Iteration:  554\n",
      "Iteration:  555\n",
      "Iteration:  556\n",
      "Iteration:  557\n",
      "Iteration:  558\n",
      "Iteration:  559\n",
      "Iteration:  560\n",
      "Iteration:  561\n",
      "Iteration:  562\n",
      "Iteration:  563\n",
      "Iteration:  564\n",
      "Iteration:  565\n",
      "Iteration:  566\n",
      "Iteration:  567\n",
      "Iteration:  568\n",
      "Iteration:  569\n",
      "Iteration:  570\n",
      "Iteration:  571\n",
      "Iteration:  572\n",
      "Iteration:  573\n",
      "Iteration:  574\n",
      "Iteration:  575\n",
      "Iteration:  576\n",
      "Iteration:  577\n",
      "Iteration:  578\n",
      "Iteration:  579\n",
      "Iteration:  580\n",
      "Iteration:  581\n",
      "Iteration:  582\n",
      "Iteration:  583\n",
      "Iteration:  584\n",
      "Iteration:  585\n",
      "Iteration:  586\n",
      "Iteration:  587\n",
      "Iteration:  588\n",
      "Iteration:  589\n",
      "Iteration:  590\n",
      "Iteration:  591\n",
      "Iteration:  592\n",
      "Iteration:  593\n",
      "Iteration:  594\n",
      "Iteration:  595\n",
      "Iteration:  596\n",
      "Iteration:  597\n",
      "Iteration:  598\n",
      "Iteration:  599\n",
      "Iteration:  600\n",
      "Epoch: 0/200 Iteration: 600 Loss: 6.849395751953125\n",
      "Iteration:  601\n",
      "Iteration:  602\n",
      "Iteration:  603\n",
      "Iteration:  604\n",
      "Iteration:  605\n",
      "Iteration:  606\n",
      "Iteration:  607\n",
      "Iteration:  608\n",
      "Iteration:  609\n",
      "Iteration:  610\n",
      "Iteration:  611\n",
      "Iteration:  612\n",
      "Iteration:  613\n",
      "Iteration:  614\n",
      "Iteration:  615\n",
      "Iteration:  616\n",
      "Iteration:  617\n",
      "Iteration:  618\n",
      "Iteration:  619\n",
      "Iteration:  620\n",
      "Iteration:  621\n",
      "Iteration:  622\n",
      "Iteration:  623\n",
      "Iteration:  624\n",
      "Iteration:  625\n",
      "Iteration:  626\n",
      "Iteration:  627\n",
      "Iteration:  628\n",
      "Iteration:  629\n",
      "Iteration:  630\n",
      "Iteration:  631\n",
      "Iteration:  632\n",
      "Iteration:  633\n",
      "Iteration:  634\n",
      "Iteration:  635\n",
      "Iteration:  636\n",
      "Iteration:  637\n",
      "Iteration:  638\n",
      "Iteration:  639\n",
      "Iteration:  640\n",
      "Iteration:  641\n",
      "Iteration:  642\n",
      "Iteration:  643\n",
      "Iteration:  644\n",
      "Iteration:  645\n",
      "Iteration:  646\n",
      "Iteration:  647\n",
      "Iteration:  648\n",
      "Iteration:  649\n",
      "Iteration:  650\n",
      "Iteration:  651\n",
      "Iteration:  652\n",
      "Iteration:  653\n",
      "Iteration:  654\n",
      "Iteration:  655\n",
      "Iteration:  656\n",
      "Iteration:  657\n",
      "Iteration:  658\n",
      "Iteration:  659\n",
      "Iteration:  660\n",
      "Iteration:  661\n",
      "Iteration:  662\n",
      "Iteration:  663\n",
      "Iteration:  664\n",
      "Iteration:  665\n",
      "Iteration:  666\n",
      "Iteration:  667\n",
      "Iteration:  668\n",
      "Iteration:  669\n",
      "Iteration:  670\n",
      "Iteration:  671\n",
      "Iteration:  672\n",
      "Iteration:  673\n",
      "Iteration:  674\n",
      "Iteration:  675\n",
      "Iteration:  676\n",
      "Iteration:  677\n",
      "Iteration:  678\n",
      "Iteration:  679\n",
      "Iteration:  680\n",
      "Iteration:  681\n",
      "Iteration:  682\n",
      "Iteration:  683\n",
      "Iteration:  684\n",
      "Iteration:  685\n",
      "Iteration:  686\n",
      "Iteration:  687\n",
      "Iteration:  688\n",
      "Iteration:  689\n",
      "Iteration:  690\n",
      "Iteration:  691\n",
      "Iteration:  692\n",
      "Iteration:  693\n",
      "Iteration:  694\n",
      "Iteration:  695\n",
      "Iteration:  696\n",
      "Iteration:  697\n",
      "Iteration:  698\n",
      "Iteration:  699\n",
      "Iteration:  700\n",
      "Epoch: 0/200 Iteration: 700 Loss: 7.347291469573975\n",
      "Iteration:  701\n",
      "Iteration:  702\n",
      "Iteration:  703\n",
      "Iteration:  704\n",
      "Iteration:  705\n",
      "Iteration:  706\n",
      "Iteration:  707\n",
      "Iteration:  708\n",
      "Iteration:  709\n",
      "Iteration:  710\n",
      "Iteration:  711\n",
      "Iteration:  712\n",
      "Iteration:  713\n",
      "Iteration:  714\n",
      "Iteration:  715\n",
      "Iteration:  716\n",
      "Iteration:  717\n",
      "Iteration:  718\n",
      "Iteration:  719\n",
      "Iteration:  720\n",
      "Iteration:  721\n",
      "Iteration:  722\n",
      "Iteration:  723\n",
      "Iteration:  724\n",
      "Iteration:  725\n",
      "Iteration:  726\n",
      "Iteration:  727\n",
      "Iteration:  728\n",
      "Iteration:  729\n",
      "Iteration:  730\n",
      "Iteration:  731\n",
      "Iteration:  732\n",
      "Iteration:  733\n",
      "Iteration:  734\n",
      "Iteration:  735\n",
      "Iteration:  736\n",
      "Iteration:  737\n",
      "Iteration:  738\n",
      "Iteration:  739\n",
      "Iteration:  740\n",
      "Iteration:  741\n",
      "Iteration:  742\n",
      "Iteration:  743\n",
      "Iteration:  744\n",
      "Iteration:  745\n",
      "Iteration:  746\n",
      "Iteration:  747\n",
      "Iteration:  748\n",
      "Iteration:  749\n",
      "Iteration:  750\n",
      "Iteration:  751\n",
      "Iteration:  752\n",
      "Iteration:  753\n",
      "Iteration:  754\n",
      "Iteration:  755\n",
      "Iteration:  756\n",
      "Iteration:  757\n",
      "Iteration:  758\n",
      "Iteration:  759\n",
      "Iteration:  760\n",
      "Iteration:  761\n",
      "Iteration:  762\n",
      "Iteration:  763\n",
      "Iteration:  764\n",
      "Iteration:  765\n",
      "Iteration:  766\n",
      "Iteration:  767\n",
      "Iteration:  768\n",
      "Iteration:  769\n",
      "Iteration:  770\n",
      "Iteration:  771\n",
      "Iteration:  772\n",
      "Iteration:  773\n",
      "Iteration:  774\n",
      "Iteration:  775\n",
      "Iteration:  776\n",
      "Iteration:  777\n",
      "Iteration:  778\n",
      "Iteration:  779\n",
      "Iteration:  780\n",
      "Iteration:  781\n",
      "Iteration:  782\n",
      "Iteration:  783\n",
      "Iteration:  784\n",
      "Iteration:  785\n",
      "Iteration:  786\n",
      "Iteration:  787\n",
      "Iteration:  788\n",
      "Iteration:  789\n",
      "Iteration:  790\n",
      "Iteration:  791\n",
      "Iteration:  792\n",
      "Iteration:  793\n",
      "Iteration:  794\n",
      "Iteration:  795\n",
      "Iteration:  796\n",
      "Iteration:  797\n",
      "Iteration:  798\n",
      "Iteration:  799\n",
      "Iteration:  800\n",
      "Epoch: 0/200 Iteration: 800 Loss: 6.838168621063232\n",
      "Iteration:  801\n",
      "Iteration:  802\n",
      "Iteration:  803\n",
      "Iteration:  804\n",
      "Iteration:  805\n",
      "Iteration:  806\n",
      "Iteration:  807\n",
      "Iteration:  808\n",
      "Iteration:  809\n",
      "Iteration:  810\n",
      "Iteration:  811\n",
      "Iteration:  812\n",
      "Iteration:  813\n",
      "Iteration:  814\n",
      "Iteration:  815\n",
      "Iteration:  816\n",
      "Iteration:  817\n",
      "Iteration:  818\n",
      "Iteration:  819\n",
      "Iteration:  820\n",
      "Iteration:  821\n",
      "Iteration:  822\n",
      "Iteration:  823\n",
      "Iteration:  824\n",
      "Iteration:  825\n",
      "Iteration:  826\n",
      "Iteration:  827\n",
      "Iteration:  828\n",
      "Iteration:  829\n",
      "Iteration:  830\n",
      "Iteration:  831\n",
      "Iteration:  832\n",
      "Iteration:  833\n",
      "Iteration:  834\n",
      "Iteration:  835\n",
      "Iteration:  836\n",
      "Iteration:  837\n",
      "Iteration:  838\n",
      "Iteration:  839\n",
      "Iteration:  840\n",
      "Iteration:  841\n",
      "Iteration:  842\n",
      "Iteration:  843\n",
      "Iteration:  844\n",
      "Iteration:  845\n",
      "Iteration:  846\n",
      "Iteration:  847\n",
      "Iteration:  848\n",
      "Iteration:  849\n",
      "Iteration:  850\n",
      "Iteration:  851\n",
      "Iteration:  852\n",
      "Iteration:  853\n",
      "Iteration:  854\n",
      "Iteration:  855\n",
      "Iteration:  856\n",
      "Iteration:  857\n",
      "Iteration:  858\n",
      "Iteration:  859\n",
      "Iteration:  860\n",
      "Iteration:  861\n",
      "Iteration:  862\n",
      "Iteration:  863\n",
      "Iteration:  864\n",
      "Iteration:  865\n",
      "Iteration:  866\n",
      "Iteration:  867\n",
      "Iteration:  868\n",
      "Iteration:  869\n",
      "Iteration:  870\n",
      "Iteration:  871\n",
      "Iteration:  872\n",
      "Iteration:  873\n",
      "Iteration:  874\n",
      "Iteration:  875\n",
      "Iteration:  876\n",
      "Iteration:  877\n",
      "Iteration:  878\n",
      "Iteration:  879\n",
      "Iteration:  880\n",
      "Iteration:  881\n",
      "Iteration:  882\n",
      "Iteration:  883\n",
      "Iteration:  884\n",
      "Iteration:  885\n",
      "Iteration:  886\n",
      "Iteration:  887\n",
      "Iteration:  888\n",
      "Iteration:  889\n",
      "Iteration:  890\n",
      "Iteration:  891\n",
      "Iteration:  892\n",
      "Iteration:  893\n",
      "Iteration:  894\n",
      "Iteration:  895\n",
      "Iteration:  896\n",
      "Iteration:  897\n",
      "Iteration:  898\n",
      "Iteration:  899\n",
      "Iteration:  900\n",
      "Epoch: 0/200 Iteration: 900 Loss: 6.2310566902160645\n",
      "Iteration:  901\n",
      "Iteration:  902\n",
      "Iteration:  903\n",
      "Iteration:  904\n",
      "Iteration:  905\n",
      "Iteration:  906\n",
      "Iteration:  907\n",
      "Iteration:  908\n",
      "Iteration:  909\n",
      "Iteration:  910\n",
      "Iteration:  911\n",
      "Iteration:  912\n",
      "Iteration:  913\n",
      "Iteration:  914\n",
      "Iteration:  915\n",
      "Iteration:  916\n",
      "Iteration:  917\n",
      "Iteration:  918\n",
      "Iteration:  919\n",
      "Iteration:  920\n",
      "Iteration:  921\n",
      "Iteration:  922\n",
      "Iteration:  923\n",
      "Iteration:  924\n",
      "Iteration:  925\n",
      "Iteration:  926\n",
      "Iteration:  927\n",
      "Iteration:  928\n",
      "Iteration:  929\n",
      "Iteration:  930\n",
      "Iteration:  931\n",
      "Iteration:  932\n",
      "Iteration:  933\n",
      "Iteration:  934\n",
      "Iteration:  935\n",
      "Iteration:  936\n",
      "Iteration:  937\n",
      "Iteration:  938\n",
      "Iteration:  939\n",
      "Iteration:  940\n",
      "Iteration:  941\n",
      "Iteration:  942\n",
      "Iteration:  943\n",
      "Iteration:  944\n",
      "Iteration:  945\n",
      "Iteration:  946\n",
      "Iteration:  947\n",
      "Iteration:  948\n",
      "Iteration:  949\n",
      "Iteration:  950\n",
      "Iteration:  951\n",
      "Iteration:  952\n",
      "Iteration:  953\n",
      "Iteration:  954\n",
      "Iteration:  955\n",
      "Iteration:  956\n",
      "Iteration:  957\n",
      "Iteration:  958\n",
      "Iteration:  959\n",
      "Iteration:  960\n",
      "Iteration:  961\n",
      "Iteration:  962\n",
      "Iteration:  963\n",
      "Iteration:  964\n",
      "Iteration:  965\n",
      "Iteration:  966\n",
      "Iteration:  967\n",
      "Iteration:  968\n",
      "Iteration:  969\n",
      "Iteration:  970\n",
      "Iteration:  971\n",
      "Iteration:  972\n",
      "Iteration:  973\n",
      "Iteration:  974\n",
      "Iteration:  975\n",
      "Iteration:  976\n",
      "Iteration:  977\n",
      "Iteration:  978\n",
      "Iteration:  979\n",
      "Iteration:  980\n",
      "Iteration:  981\n",
      "Iteration:  982\n",
      "Iteration:  983\n",
      "Iteration:  984\n",
      "Iteration:  985\n",
      "Iteration:  986\n",
      "Iteration:  987\n",
      "Iteration:  988\n",
      "Iteration:  989\n",
      "Iteration:  990\n",
      "Iteration:  991\n",
      "Iteration:  992\n",
      "Iteration:  993\n",
      "Iteration:  994\n",
      "Iteration:  995\n",
      "Iteration:  996\n",
      "Iteration:  997\n",
      "Iteration:  998\n",
      "Iteration:  999\n",
      "Iteration:  1000\n",
      "Epoch: 0/200 Iteration: 1000 Loss: 6.517038822174072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________ Mermaid Man: Oh, this was a great idea! I got a Krabby Patty] I can't be my own new time to do it. Mr. Krabs. Mr. Krabs. SpongeBob: Oh, no. Mr. Krabs, we don't need you to get me your old more of a bunch for your old more day to get the king time I don't know how do you think we do you like you have you have an idea! Squidward: You can do it on to show you have a bunch to a few life of this time, SpongeBob: You got to do that. SpongeBob: I thought I\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoint_pt/model-1000.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b3f09d6850bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_to_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_to_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'checkpoint_pt/model-{}.pth'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpoint_pt/model-1000.pth'"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "for e in range(50):\n",
    "    print('Epoch: ', e)\n",
    "    batches = get_batches(in_text, out_text, flags.batch_size, flags.seq_size)\n",
    "    state_h, state_c = net.zero_state(flags.batch_size)\n",
    "    \n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    for x, y in batches:\n",
    "        iteration += 1\n",
    "        print('Iteration: ', iteration)\n",
    "        \n",
    "        # train\n",
    "        net.train()\n",
    "        \n",
    "        # reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = torch.tensor(x).to(device)\n",
    "        y = torch.tensor(y).to(device)\n",
    "            \n",
    "        logits, (state_h, state_c) = net(x, (state_h, state_c))\n",
    "        loss = criterion(logits.transpose(1,2), y)\n",
    "        \n",
    "        # detach() so pytorch can calculate loss\n",
    "        state_h = state_h.detach()\n",
    "        state_c = state_c.detach()\n",
    "        \n",
    "        loss_value = loss.item()\n",
    "        \n",
    "        # back propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient clipping \n",
    "        _ = torch.nn.utils.clip_grad_norm_(net.parameters(), flags.gradients_norm)\n",
    "        \n",
    "        # update network parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss values to the console during training\n",
    "        if iteration % 100 == 0:\n",
    "            print('Epoch: {}/{}'.format(e, 200),\n",
    "                  'Iteration: {}'.format(iteration),\n",
    "                  'Loss: {}'.format(loss_value))\n",
    "        \n",
    "        # print a little sample of text during training\n",
    "        if iteration % 1000 == 0:\n",
    "            predict(device, net, flags.initial_words, n_vocab, vocab_to_int, int_to_vocab, top_k=5)\n",
    "            torch.save(net.state_dict(), 'checkpoint_pt/model-{}-{}.pth'.format(iteration, loss_value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
